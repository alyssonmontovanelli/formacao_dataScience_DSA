print(!x > 8)
# Criando Variáveis
var1 = 100
print(var1)
mode(var1)
help('mode')
sqrt(var1)
# Atribuir valor de variavel em outra variavel
var2 = var1
var2
typeof(var2)
mode(var2)
# Lista de elementos
var3 = c('primeiro', 'segundo', 'terceiro')
mode(var3)
typeof(var3)
# Chamando uma função
var4 = function(x){x+3}
var4
mode(var4)
var4(3)
var4(10)
# Mudar o modo do dado
var1
var5 = as.character(var1)
var5
mode(var5)
x
# Atribuindo valores a objetos
x <- c(1,2,3)
x
x
x1 = c(1,2,3)
x1
mode(x)
mode(x1)
typeof(x)
typeof(x1)
c(1,2,3) -> y
y
assign("x", c(6.3, 8.9, -6))
x
x
x[0]
x[1]
# Verifica objetos
ls()
objects()
2+2
4-9
2+2
getwd() # Visualiza diretório
license() # licença
print('Estou iniciando os estudos com a linguagem R')
getwd() # Visualiza diretório
sessionInfo() # Resumo sobre a sessão
print('Estou iniciando os estudos com a linguagem R')
# Carregando pacote da memória
library(ggplot2)
# Instalando pacotes
install.packages('randomForest')
install.packages('ggplot2')
install.packages('dplyr')
install.packages("ggplot2")
# Criando gráfico
plot(1:25)
# Criando gráfico
plot(1:25:2)
# Criando gráfico
plot(1:25:5)
# Criando gráfico
plot(1:25:15)
# Carregando pacote da memória
library(ggplot2)
install.packages('ggplot2')
install.packages("ggplot2")
install.packages("caret")
# Instalando pacotes
install.packages('randomForest')
install.packages('ggplot2')
install.packages('dplyr')
install.packages('devtools')
# Carregando pacote da memória
library(ggplot2)
# Descarregar o pacote
detach(package:ggplot2)
# Se souber o nome da função
help(sum)
# Se souber o nome da função
help(mean)
# Se souber o nome da função
help(library)
# Para buscar mais opçoes sobre uma função, podemos utilizar o SOS
install.packages("sos")
library(sos)
findFn("fread")
# Se souber o nome da função
help.search('randomForest')
help.search('matplot')
??matplot # Outra forma de chamar o help
example('matplot') # Exemplo de utilização da função matplot
# Sair
q()
install.packages('ggplot2')
library(ggplot2)
# Plotando um grfico básico com qplot()
data(tips, package = 'reshape2')
View(tips)
qplot(total_bill, tip, data = tips, geom = "point")
# Camada 1
camada1 <- geom_point(
mapping = aes(x = total_bill, y = tip, color = sex),
data = tips,
size = 3
)
ggplot() + camada1
# Construindo um modelo de regressão linear
modelo_base <- lm(tip ~ total_bill, data = tips)
modelo_fit <- data.frame(
total_bill = tips$total_bill,
predict(modelo_base, interval = "confidence")
)
head(modelo_fit)
# Camada 2
camada2 <- geom_line(
mapping = aes(x = total_bill, y = fit),
data = modelo_fit,
color = 'darkgreen'
)
ggplot() + camada1 + camada2
# Camada 3
camada3 <- geom_ribbon(
mapping = aes(x = total_bill, ymin = lwr, ymax = upr),
data = modelo_fit,
alpha = 0.3
)
ggplot() + camada1 + camada2 + camada3
# Camada 3
camada3 <- geom_ribbon(
mapping = aes(x = total_bill, ymin = lwr, ymax = upr),
data = modelo_fit,
alpha = 0.4
)
ggplot() + camada1 + camada2 + camada3
# VERSÃO FINAL COM OTIMIZAÇÃO
ggplot(tips, aes(x = total_bill, y = tip)) +
geom_point(aes(color = sex)) +
geom_smooth(method = 'lm')
data = data.frame(cond = rep(c("Obs 1", "Obs 2"),
each = 10), var = 1:100 +
rnorm(100, sd = 9), var2 = 1:100 +
rnorm(100, sd = 16))
data = data.frame(cond = rep(c("Obs 1", "Obs 2"),
each = 10), var = 1:100 +
rnorm(100, sd = 9), var2 = 1:100 +
rnorm(100, sd = 16))
# VERSÃO FINAL COM OTIMIZAÇÃO
ggplot(tips, aes(x = total_bill, y = tip)) +
geom_point(aes(color = sex)) +
geom_smooth(method = 'lm')
data = data.frame(cond = rep(c("Obs 1", "Obs 2"),
each = 10), var = 1:100 +
rnorm(100, sd = 9), var2 = 1:100 +
rnorm(100, sd = 16))
data = data.frame(cond = rep(c("Obs 1", "Obs 2"),
each = 10), var = 1:100 +
rnorm(100, sd = 9), var2 = 1:100 +
rnorm(100, sd = 16))
data
# Dados
data = data.frame(cond = rep(c("Obs 1", "Obs 2"),
each = 10), var1 = 1:100 +
rnorm(100, sd = 9), var2 = 1:100 +
rnorm(100, sd = 16))
# Plotagem
ggplot(data, aes(x = var1, y = var2))
# Plotagem
ggplot(data, aes(x = var1, y = var2)) + geom_point(shape = 1) +
geom_smooth(method = , color = "red", se = FALSE)
# Dados
data = data.frame(grupo = c('A', 'B', 'C', 'D'),
valor = c(33,62,56,67),
num_obs = c(100, 500, 459, 340))
# Gerando massa de dados
data$right = cumsum(data$num_obs) + 30 * c(0:(nrow(data)-1))
data$
data$right
data$left = data$right - data$num_obs
data
View(dataset_bank)
# Carregando dados
dataset_bank <- read.table("C:\formacao_dataScience_DSA_DADOS\04_machineLearning\Cap02\bank\bank-full.csv",
View(dataset_bank)
# Carregando dados
dataset_bank <- read.table("C:/formacao_dataScience_DSA_DADOS/04_machineLearning/Cap02/bank/bank-full.csv",
header = TRUE, sep = ";")
View(dataset_bank)
round(dataset_bank)
# função table() para conhecer melhor os dados
table(dataset_bank$job)
# Visualizando os valores da tabela de forma gráfica
library(dplyr)
library(ggplot2)
dataset_bank %>%
group_by(job)%.%
summarise(n = n())%>%
ggplot(aes(x = job, y = n))+
geom_bar(start = "identity")+
theme(axis.text.x = element_text(angle = 90, hjust = 1))
# Visualizando os valores da tabela de forma gráfica
library(dplyr)
library(ggplot2)
dataset_bank %>%
group_by(job)%.%
summarise(n = n())%>%
ggplot(aes(x = job, y = n))+
geom_bar(start = "identity")+
theme(axis.text.x = element_text(angle = 90, hjust = 1))
dataset_bank %>%
group_by(job)%>%
summarise(n = n())%>%
ggplot(aes(x = job, y = n))+
geom_bar(start = "identity")+
theme(axis.text.x = element_text(angle = 90, hjust = 1))
dataset_bank %>%
group_by(job)%>%
summarise(n = n())%>%
ggplot(aes(x = job, y = n))+
geom_bar(start = "identity")+
theme(axis.text.x = element_text(angle = 90, hjust = 1))
dataset_bank %>%
group_by(job)%>%
summarise(n = n())%>%
ggplot(aes(x = job, y = n))+
geom_bar(stat = "identity")+
theme(axis.text.x = element_text(angle = 90, hjust = 1))
dataset_bank %>%
group_by(job)%>%
summarise(n = n())%>%
ggplot(aes(x = job, y = n))+
geom_bar(stat = "identity")+
theme(axis.text.x = element_text(angle = 60, hjust = 1))
dataset_bank %>%
group_by(job)%>%
summarise(n = n())%>%
ggplot(aes(x = job, y = n))+
geom_bar(stat = "identity")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Adicionando nova coluna ao conjunto de dados com o mutate()
dataset_bank <- dataset_bank %>%
mutate(technology_use =
case_when(job == 'admin' ~ 'medio',
job == 'admin' ~ 'medio',
job == 'admin' ~ 'medio',))
# Adicionando nova coluna ao conjunto de dados com o mutate()
dataset_bank <- dataset_bank %>%
mutate(technology_use =
case_when(job == 'admin' ~ 'medio',
job == 'blue-collar' ~ 'baixo',
job == 'entrepreneur' ~ 'alto',
job == 'housemaid' ~ 'baixo',
job == 'management' ~ 'medio',
job == 'retired' ~ 'baixo',
job == 'self-employed' ~ 'baixo',
job == 'services' ~ 'medio',
job == 'student' ~ 'alto',
job == 'technician' ~ 'alto',
job == 'unemployed' ~ 'baixo',
job == 'unknown' ~ 'baixo'))
View(dataset_bank)
# PLotando nova coluna
dataset_bank %>%
group_by(technology_use)%>%
summarise(n = n())%>%
ggplot(aes(x = technology_use, y = n))+
geom_bar(stat = "Conhecimento em Tecnologia")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# PLotando nova coluna
dataset_bank %>%
group_by(technology_use)%>%
summarise(n = n())%>%
ggplot(aes(x = technology_use, y = n))+
geom_bar(stat = "identity")+
theme(axis.text.x = element_text(angle = 45, hjust = 1))
######################################################
dataset_bank <- dataset_bank %>%
mutate(defaulted = ifelse(default == 'yes', 1, 0))
View(data)
View(dataset_bank)
library(caret)
bank.dummies <- data.frame(predict(dmy, newdata = dataset_bank))
dmy <- dummyVars(" ~ .", data = dataset_bank)
bank.dummies <- data.frame(predict(dmy, newdata = dataset_bank))
View(bank.dummies)
dataset_bank %>%
group_by(job, maritial)%>%
summarise(n = n())
dataset_bank %>%
group_by(job, marital)%>%
summarise(n = n())
dataset_bank %.%
group_by(job, martial) %>%
summarise(n=n()) %>%
ggplot(aes(x = job, y = n, fill = marital))+
geom_bar(stat = 'identity', position = 'dodge')+
theme(axis.text.x = element_text(angle = 60, hjust = 1))
dataset_bank %>%
group_by(job, martial) %>%
summarise(n=n()) %>%
ggplot(aes(x = job, y = n, fill = marital))+
geom_bar(stat = 'identity', position = 'dodge')+
theme(axis.text.x = element_text(angle = 60, hjust = 1))
dataset_bank %>%
group_by(job, martial) %>%
summarise(n=n()) %>%
ggplot(aes(x = job, y = n, fill = marital))+
geom_bar(stat = 'identity', position = 'dodge')+
theme(axis.text.x = element_text(angle = 60, hjust = 1))
dataset_bank %>%
group_by(job, marital) %>%
summarise(n=n()) %>%
ggplot(aes(x = job, y = n, fill = marital))+
geom_bar(stat = 'identity', position = 'dodge')+
theme(axis.text.x = element_text(angle = 60, hjust = 1))
# Utilizando dummyVars nesse conjunto sumarizado
dmy <- dummyVars( ~ job:marital, data = dataset_bank)
bank.cross <- predict(dmy, newdata = dataset_bank)
View(bank.cross)
setwd('C:/formacao_dataScience_DSA/04_machineLearning/Cap06_KNN_Classificador_K-Nearest-Neighbours')
getwd()
setwd('C:/formacao_dataScience_DSA/04_machineLearning/Cap06_KNN_Classificador_K-Nearest-Neighbours')
# instalando pacotes
install.packages('ISLR')
install.packages('caret')
install.packages('e1071')
# Carregando pacotes
library(ISLR)
library(caret)
library(e1071)
# Definindo o seed
set.seed(300)
# Carregando o dataset e explorando
summary(Smarket)
# Carregando o dataset e explorando
summary(Smarket)
str(Smarket)
head(Smarket)
# SPLIT do dataset em treino e teste
indxTrain <- createDataPortition(y = Smarket$Direction, p= 0.75, list = FALSE)
# instalando pacotes
install.packages('ISLR')
install.packages('caret')
install.packages('e1071')
install.packages("ISLR")
# Carregando pacotes
library(ISLR)
library(caret)
library(e1071)
# Definindo o seed
set.seed(300)
# Carregando o dataset e explorando
summary(Smarket)
str(Smarket)
head(Smarket)
# SPLIT do dataset em treino e teste
indxTrain <- createDataPortition(y = Smarket$Direction, p= 0.75, list = FALSE)
# SPLIT do dataset em treino e teste
indxTrain <- createDataPartition(y = Smarket$Direction, p= 0.75, list = FALSE)
View(indxTrain)
dados_treino <- Smarket[indxTrain,]
dados_teste <- Smarket[-indxTrain,]
# Verificando a distribuição dos dados originais e das partições
prop.table(table(Smarket$Direction)) * 100
prop.table(table(dados_treino$Direction)) * 100
# Correlação entre as variáveis preditoras
descrCor <- cor(dados_treino[,names(dados_treino)] != "Direction")
descrCor
# Correlação entre as variáveis preditoras
descrCor <- cor(dados_treino[,names(dados_treino) != "Direction"])
descrCor
descrCor
descrCor
# REMOVENDO A VARIÁVEL TARGET DOS DADOS DE TREINO E TESTE
numeric.vars_treino <- colnames(treinoX <- dados_treino[,names{dados_treino} != "Direction"])
# REMOVENDO A VARIÁVEL TARGET DOS DADOS DE TREINO E TESTE
numeric.vars_treino <- colnames(treinoX <- dados_treino[,names(dados_treino) != "Direction"])
numeric.vars_treino <- colnames(treinoX <- dados_teste[,names(dados_teste) != "Direction"])
# Aplicando normalização às variáveis preditoras de treino e teste
dados_treino_scaled <- scale.features(dados_treino, numeric.vars_treino)
# Aplicando normalização às variáveis preditoras de treino e teste
dados_treino_scaled <- scale.features(dados_treino, numeric.vars_treino)
dados_teste_scaled <- scale.features(dados_teste, numeric.vars_teste)
View(dados_treino_scaled)
View(dados_teste_scaled)
return(df)
# Aplicando normalização às variáveis preditoras de treino e teste
dados_treino_scaled <- scale.features(dados_treino, numeric.vars_treino)
# Função de Normalização
scale.features <- function(df, variables){
for (variable in variables){
df[[variable]] <- scale(df[[variable]], center = T, scale = T)
}
return(df)
}
# Aplicando normalização às variáveis preditoras de treino e teste
dados_treino_scaled <- scale.features(dados_treino, numeric.vars_treino)
dados_teste_scaled <- scale.features(dados_teste, numeric.vars_teste)
# REMOVENDO A VARIÁVEL TARGET DOS DADOS DE TREINO E TESTE
numeric.vars_treino <- colnames(treinoX <- dados_treino[,names(dados_treino) != "Direction"])
numeric.vars_teste <- colnames(treinoX <- dados_teste[,names(dados_teste) != "Direction"])
# Aplicando normalização às variáveis preditoras de treino e teste
dados_treino_scaled <- scale.features(dados_treino, numeric.vars_treino)
dados_teste_scaled <- scale.features(dados_teste, numeric.vars_teste)
View(dados_treino_scaled)
View(dados_teste_scaled)
############## ------------------------------------
# Classificação KNN em R - Construção e Treinamento do Modelo
set.seed(400)
?trainControl
# Arquivo de CONTROLE
ctrl <- trainControl(method = "repeatedcv", repeats = 5)
# --------------------- CRIAÇÃO DO MODELO -------------------------#
knn_v1 <- train(Direction ~ .,
data = dados_treino_scaled,
method = "knn",
trControl = ctrl,
# preProcess = c("center","scale"), # Isso é a normalização
tuneLength = 20)
knn_v1
# MODELO KNN
knn_v1
# PLOTAGEM
plot(knn_v1)
# Fazendo previsões
knnPredict <- predict(knn_v1, newdata = dados_testes_scaled)
# Fazendo previsões
knnPredict <- predict(knn_v1, newdata = dados_teste_scaled)
knnPredict
# Criando MATRIX DE CONFUSÃO
confusionMatrix(knnPredict, dados_teste$Direction)
# Arquivo de controle
ctrl <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary)
# Treinamento do modelo
knn_v2 <- train(Direction ~ .,
data = dados_treino_scaled,
method = 'knn',
metric = "ROC", # essa é a mudança, nao usaremos apenas acuracia
tuneLength = 20)
# Treinamento do modelo
knn_v2 <- train(Direction ~ .,
data = dados_treino_scaled,
method = 'knn',
trControl = ctrl,
metric = "ROC", # essa é a mudança, nao usaremos apenas acuracia
tuneLength = 20)
# MODELO KNN
knn_v2
# Numero de vizinhos x Aacurácia
plot(knn_v2, print.thres = 0.5, type = "S")
# Criando confusion Matrix
conusionMatrix(knnPredict, dados_teste$Direction)
# Criando confusion Matrix
confusionMatrix(knnPredict, dados_teste$Direction)
# Arquivo de controle
ctrl <- trainControl(method = "repeatedcv",
repeats = 5,
classProbs = TRUE,
summaryFunction = twoClassSummary)
# Treinamento do modelo
knn_v2 <- train(Direction ~ .,
data = dados_treino_scaled,
method = 'knn',
trControl = ctrl,
metric = "ROC", # essa é a mudança, nao usaremos apenas acuracia
tuneLength = 20)
# MODELO KNN
knn_v2
# MODELO KNN
knn_v2
# Numero de vizinhos x Aacurácia
plot(knn_v2, print.thres = 0.5, type = "S")
# Criando confusion Matrix
confusionMatrix(knnPredict, dados_teste$Direction)
# Preparando dados de entrada
Year = c(2006, 2007, 2008)
Lag1 = c(1.30, 0.09, -0.654)
Lag2 = c(1.483, -0.198, 0.589)
Lag3 = c(-0.345, 0.029, 0.690)
Lag4 = c(1.398, 0.104, 1.483)
Lag5 = c(0.214, 0.105, 0.589)
Volume = c(1.36890, 1.09876, 1.231233)
Today = c(0.289, -0.497, 1.649)
novos_dados = data.frame(Year, Lag1, Lag2, Lag3, Lag4, Lag5, Volume, Today)
novos_dados
str(novos_dados)
class(novos_dados)
# Extraindo os nomes das variáveis
nomes_variaveis <- colnames(novos_dados)
# Extraindo os nomes das variáveis
nomes_variaveis <- colnames(novos_dados)
nomes_variaveis
# Aplicando a função
novos_dados_scaled <- scale.features(novos_dados, nomes_variaveis)
novos_dados_scaled
str(novos_dados_scaled)
class(novos_dados_scaled)
# Fazendo previsões
knnPredict <- predict(knn_v2, newdata = novos_dados_scaled)
cat(sprintf("\n Previsão de \"%s\" é \"%s\"\n", novos_dados$Year, knnPredict))
